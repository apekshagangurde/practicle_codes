<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML4 - KMeans Clustering with Iris Dataset</title>
    <link rel="stylesheet" href="ml4-style.css">
</head>
<body>
    <style>
        button {
            background-color: #3498db;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 1em;
            padding: 12px 20px;
            transition: background-color 0.3s;
            display: block;
            margin: 20px auto;
        }
        
        button:hover {
            background-color: #2980b9;
        }
    </style>
    <div class="container">
        <h1>KMeans Clustering with Iris Dataset</h1>
        <h2>Download the Dataset and Code</h2>
  
    <a href="./ML/Clustering.ipynb" download>
        <button>Download clustering Code</button>
    </a>
        <p>This page demonstrates the application of KMeans clustering on the famous Iris dataset to determine the optimal number of clusters using the elbow method.</p>

        <section class="code-section">
            <h2>Python Code</h2>
            <button class="copy-btn" onclick="copyCode()">Copy Code</button>
            <pre><code id="codeBlock">
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.datasets import load_iris

# Load the Iris dataset
df = pd.read_csv("./datasets/iris.csv")
# Load the Iris dataset or or

#iris = load_iris()
#df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
#X = df

# Select features for clustering (sepal_length, sepal_width, petal_length, petal_width)
X = df.iloc[:, 1:-1]  # Exclude ID and species columns

# Standardize the feature matrix (important for K-Means)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimal number of clusters using the elbow method
inertia = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), inertia, marker='o', linestyle='--')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia (Within-cluster Sum of Squares)')
plt.title('Elbow Method for Optimal Number of Clusters')
plt.grid()
plt.show()

'''K-Means is a popular clustering algorithm used
to partition data into K distinct clusters based on feature similarity.

 Here are the steps involved:

1. Choose the Number of Clusters (K):

 by using methods like the elbow method.

2. Initialize Centroids:

Randomly select K data points from the dataset as initial centroids (the center of each cluster).


3. Assign Clusters:

For each data point, calculate the distance to each centroid (using Euclidean distance is common) and assign the data point to the cluster with the nearest centroid.

4. Update Centroids:

Recalculate the centroids by taking the mean of all data points assigned to each cluster.

5. Repeat:

Repeat steps 3 and 4 until convergence is reached 



6. Final Output:

Once the algorithm has converged, the final clusters and centroids are returned.




Elbow Method:

The elbow method is a heuristic used to determine the optimal number of clusters (K) for K-Means clustering. Here's how it works:

1. Calculate K-Means for a Range of K Values:

Run the K-Means algorithm for a range of K values (e.g., from 1 to 10).



2. Calculate the Sum of Squared Errors (SSE):

For each value of K, calculate the sum of squared distances (errors) between each data point and its assigned centroid. This is also known as the within-cluster sum of squares (WCSS).



3. Plot the Elbow Curve:

Create a plot of the SSE against the number of clusters (K).



4. Identify the Elbow Point:

The plot will typically show a decrease in SSE as K increases. The point at which the decrease in SSE starts to slow down significantly (forming an "elbow" shape) indicates the optimal number of clusters. This is where adding more clusters provides diminishing returns on the reduction of SSE.





---

Summary:

K-Means is a simple yet effective clustering algorithm that involves initializing centroids, assigning clusters, updating centroids, and repeating until convergence.

The elbow method helps determine the appropriate number of clusters by plotting the SSE and looking for an elbow point where adding more clusters yields less improvement in SSE.


Using these methods, you can effectively cluster data and choose the number of clusters that best represents the underlying structure of the data.'''

            </code></pre>
        </section>

        <section class="plot-section">
            <h2>Elbow Curve</h2>
            <p>The elbow curve below shows the inertia values for different cluster counts. The "elbow" point indicates the optimal number of clusters.</p>
            <img src="elbow_curve_placeholder.png" alt="Elbow Curve Plot" class="plot-image">
        </section>
    </div>

    <script>
        function copyCode() {
            // Select the code text
            const codeBlock = document.getElementById("codeBlock").innerText;
            navigator.clipboard.writeText(codeBlock)
                .then(() => {
                    alert("Code copied to clipboard!");
                })
                .catch((err) => {
                    alert("Failed to copy code: ", err);
                });
        }
    </script>
</body>
</html>
